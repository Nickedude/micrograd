# Introduction
This is my implementation of micrograd, a tiny autograd engine originally built by Andrej Karpathy.

The purpose of this library is to provide a simple way to understand backpropagation (and the chain-rule).
Therefore it only operates on scalars, as opposed to tensors.
However, it does contain all the necessary components to train a small neural network.

Instructions can be found here: https://youtu.be/VMj-3S1tku0
